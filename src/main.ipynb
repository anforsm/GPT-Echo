{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from encodec import EncodecModel\n",
    "from encodec.utils import convert_audio\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.version.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodec_model = EncodecModel.encodec_model_24khz()\n",
    "encodec_model.set_target_bandwidth(1.5)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"anforsm/distilgpt2-finetuned-common-voice\")\n",
    "#model_name = \"Ekgren/text-audio-distilgpt2\"\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"Ekgren/distilgpt2-finetuned-common-voice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "text = 'text: i am taking out the trash\\nsound:'\n",
    "tokenized = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(tokenized[\"input_ids\"], do_sample=True, max_length=1024, temperature=1, top_k=50, top_p=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(tokens):\n",
    "    decoded = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "    # Get all audio_token_\n",
    "    pattern = r'audio_token_(\\d+)'\n",
    "    audio_tokens = re.findall(pattern, decoded)\n",
    "    audio_tokens = [int(token) for token in audio_tokens]\n",
    "\n",
    "    print(audio_tokens)\n",
    "\n",
    "    number_of_codebooks = 2\n",
    "    number_of_samples = len(audio_tokens) // number_of_codebooks\n",
    "    frame = torch.zeros(1, number_of_codebooks, number_of_samples, dtype=torch.long)\n",
    "    for sample in range(number_of_samples):\n",
    "        for codebook in range(number_of_codebooks):\n",
    "            frame[0, codebook, sample] = audio_tokens[sample * number_of_codebooks + codebook]\n",
    "    \n",
    "    frames = [(frame, None)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        wav = encodec_model.decode(frames)\n",
    "\n",
    "    torchaudio.save(\"output.wav\", wav[0, :, :], encodec_model.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62, 913, 62, 424, 62, 424, 62, 424, 408, 544, 408, 544, 62, 424, 408, 913, 408, 913, 465, 860, 592, 60, 278, 725, 158, 86, 544, 123, 12, 22, 476, 437, 321, 349, 224, 390, 491, 717, 276, 991, 59, 336, 790, 702, 986, 702, 563, 349, 931, 317, 796, 728, 866, 702, 766, 847, 766, 22, 766, 881, 74, 307, 18, 368, 609, 728, 766, 881, 12, 368, 487, 361, 766, 16, 311, 349, 86, 454, 906, 459, 944, 468, 303, 808, 303, 716, 303, 728, 303, 219, 303, 336, 53, 266, 53, 219, 373, 920, 373, 898, 103, 857, 373, 898, 533, 645, 476, 195, 952, 677, 920, 311, 43, 578, 858, 931, 696, 116, 875, 770, 347, 622, 971, 73, 875, 752, 777, 872, 323, 864, 91, 350, 523, 436, 656, 797, 605, 745, 312, 619, 605, 621, 648, 359, 626, 53, 86, 233, 636, 656, 597, 433, 638, 195, 280, 410, 551, 655, 605, 406, 464, 451, 626, 260, 86, 451, 312, 405, 778, 227, 312, 295, 651, 815, 491, 942, 953, 6, 59, 179, 505, 351, 3, 96, 86, 107, 912, 192, 760, 437, 929, 390, 467, 944, 306, 429, 704, 269, 186, 317, 306, 317, 530, 35, 311, 951, 80, 429, 80, 613, 224, 473, 604, 877, 1017, 580, 537, 765, 103, 243, 677, 1010, 764, 466, 191, 311, 306, 67, 864, 659, 424, 231, 197, 351, 197, 654, 796, 654, 921, 572, 881, 35, 881, 406, 224, 54, 724, 373, 876, 752, 835, 496, 339, 960, 834, 770, 408, 544, 62, 518, 408, 913, 408, 913, 408, 913, 408, 518, 62, 424, 62, 424, 62, 424, 62, 424, 106, 424, 602, 241, 602, 722, 475, 1007, 472, 743, 942, 35, 766, 655, 3, 123, 890, 202, 953, 9, 953, 265, 875, 810, 945, 763, 70, 151, 306, 613, 563, 874, 858, 793, 143, 147, 570, 839, 131, 839, 131, 743, 432, 71, 430, 458, 1017, 404, 475, 870, 475, 870, 835, 870, 835, 913, 408, 424, 738, 424, 855, 752, 25, 364, 38, 645, 38, 645, 677, 645, 537, 364, 472, 580, 25, 580, 475, 364, 131, 580, 312, 1009, 605, 991, 80, 690, 131, 839, 687, 192, 651, 674, 255, 261, 570, 143, 875, 1009, 953, 840, 991, 567, 80, 986, 255, 1003, 143, 828, 570, 564, 672, 533, 672, 533, 875, 363, 604, 363, 604, 687, 583, 436, 604, 700, 224, 436, 224, 436, 604, 877, 1019, 419, 1019, 419, 1017, 363, 1017, 363, 62, 424, 62, 424, 408, 518, 408, 913, 62, 424, 62, 424, 62, 424]\n"
     ]
    }
   ],
   "source": [
    "decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63, 937, 835, 740, 835, 302, 339, 913, 1019, 747, 228, 601, 875, 646, 670, 815, 672, 777, 570, 815, 86, 986, 767, 572, 644, 711, 621, 881, 996, 881, 278, 881, 39, 940]\n"
     ]
    }
   ],
   "source": [
    "decode([tokenizer(\"My name is Teven and I am not a woman.\\nsound: audio_token_63audio_token_937audio_token_835audio_token_740audio_token_835audio_token_302audio_token_339audio_token_913audio_token_1019audio_token_747audio_token_228audio_token_601audio_token_875audio_token_646audio_token_670audio_token_815audio_token_672audio_token_777audio_token_570audio_token_815audio_token_86audio_token_986audio_token_767audio_token_572audio_token_644audio_token_711audio_token_621audio_token_881audio_token_996audio_token_881audio_token_278audio_token_881audio_token_39audio_token_940\")[\"input_ids\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
